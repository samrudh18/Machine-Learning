# Machine-Learning

# CS771-Intro-to-Machine-Learning

This repository contains the implementation and analysis of multiple Machine Learning algorithms. The repository includes two types of documents, ### Questions and ### Jupyter Notebooks containing the solutions. The algorithms and environments have been implemented in Python using the following libraries: Numpy, Matplotlib, Pandas, Copy, Time and scikit-learn (only for verification). All of the above was done as a part of the CS771-Introduction to Machine Learning course instructed by Prof Nisheeth Srivastava at IIT Kanpur (Fall-2021). 

## [Assignment - 1] (CS771-Assignment-1-Notebook.ipynb)

Contains the implementation and analysis of:

#### Part-1
a) EDA
	i) [Automobile Dataset] (https://www.kaggle.com/datasets/toramky/automobile-dataset)
b)  Model
	i) K-NN (Cross validation + Regularisation) 
c) Evaluation
	i) Accuracy
	ii) Feature Importance

#### Part-2
a) EDA
	i) [Adult Income Dataset](https://www.kaggle.com/datasets/wenruliu/adult-income-dataset)
b)  Model
	i) Vanilla Decision Tree 
	ii) Decision Tree with prototype splitting criteria 
c) Evaluation
	i) Accuracy

## [Assignment - 2] (CS771-Assignment-2-Notebook.ipynb)

Contains the implementation and analysis of:

#### Part-1
a) Functions
	i) Convex function
	ii) Non-convex function
	iii) Linear Regression
b) Optimisation
	i) Gradient Descent
	ii) Mini-batch Stochastic Gradient Descent
c) Bayesian network

## [Assignment - 3] (CS771-Assignment-3-Notebook.ipynb)

Contains the implementation and analysis of:

#### Part-1
a) EDA
	[Bank-note-authentication-dataset]
(https://www.kaggle.com/datasets/ritesaluja/bank-note-authentication-uci-data)
b) Model
	i) Perceptron
c) Evaluation
	i) F-score

#### Part-2
a) Models
	i) Bayesian inference (analytical implementation)
	ii) Bayesian inference (MCMC Sampling)
b) Evaluation
	i) Runtime
	ii) Accuracy
	iii) KL Divergence

## [Assignment - 4] (CS771-Assignment-4-Notebook.ipynb) 

Contains the implementation and analysis of:

#### Part-1
a) Dataset
	i) Smiley dataset
b) Models
	i) k-means
	ii) k-means ++
	ii) Kernel k-means (Gaussian kernel)
c) Evaluation
	i) Visualisation
	ii) Error
	iii) AIC

#### Part-2
a) Data
	i) Gaussian distributions (Synthetically generated)
b) Model 
	i) Derivation and implementation of Gaussian mixture models (Expectation-Maximisation)


